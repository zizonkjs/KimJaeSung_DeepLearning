{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 모델 클래스\n",
    "- 부모클래스 : nn.Module\n",
    "- 필수오버라이딩 :   \n",
    "    *__int__() : 모델 층 구성, 설계  \n",
    "    *forward() : 순방향 학습 진행 코드 구현  \n",
    "-동적 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모듈로딩\n",
    "import torch    # 텐서 관련 모듈\n",
    "import torch.nn as nn # 인공신경망 관련 모듈\n",
    "import torch.nn.functional as F # 인공신경망 관련 함수들 모듈 ( 손실 함수, 활성화함수 등등 )\n",
    "import torch.optim as optim # 최적화 관련 모듈 ( 가중치 , 절편 빠르게 찾아주는 알고리즘 )\n",
    "from torchinfo import summary # 모델 구조 및 저보 관련 모듈\n",
    "from torchmetrics.regression import * # 회귀 성능 관련\n",
    "from torchmetrics.classification import * # 분류 성능 관련\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "# 텐서 저장 및 실행 위치설정\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 설계 ( 동적 모델 )\n",
    "- 목표 : 은닉층의 개수가 동적인 모델\n",
    "- 조건\n",
    "    * 입력층과 출력층 개수 동적 => 입력층의 입력값, 출력층의 출력값이 필요함   \n",
    "    * 은닉층의 개수 동적 + 퍼셉트론 개수 고정 => 은닉층의 개수, 퍼셉트론 수  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_layer.weight torch.Size([5, 3])\n",
      "in_layer.bias torch.Size([5])\n",
      "h_layers.0.weight torch.Size([5, 5])\n",
      "h_layers.0.bias torch.Size([5])\n",
      "h_layers.1.weight torch.Size([5, 5])\n",
      "h_layers.1.bias torch.Size([5])\n",
      "h_layers.2.weight torch.Size([5, 5])\n",
      "h_layers.2.bias torch.Size([5])\n",
      "h_layers.3.weight torch.Size([5, 5])\n",
      "h_layers.3.bias torch.Size([5])\n",
      "h_layers.4.weight torch.Size([5, 5])\n",
      "h_layers.4.bias torch.Size([5])\n",
      "h_layers.5.weight torch.Size([5, 5])\n",
      "h_layers.5.bias torch.Size([5])\n",
      "h_layers.6.weight torch.Size([5, 5])\n",
      "h_layers.6.bias torch.Size([5])\n",
      "h_layers.7.weight torch.Size([5, 5])\n",
      "h_layers.7.bias torch.Size([5])\n",
      "h_layers.8.weight torch.Size([5, 5])\n",
      "h_layers.8.bias torch.Size([5])\n",
      "h_layers.9.weight torch.Size([5, 5])\n",
      "h_layers.9.bias torch.Size([5])\n",
      "out_layer.weight torch.Size([2, 5])\n",
      "out_layer.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#  모델 이름 : DynamicModel\n",
    "#  모델의 매개변수 : in_in, out_out, h_inout, h_cnt\n",
    "#  동적 모델 \n",
    "#   container 모듈 중. nn.ModuleList() 사용해서 동적으로 Layer 추가\n",
    "#       forwoard 기능 미 제공\n",
    "#       layer 인스턴스 요소 사이에 연관성 없음\n",
    "#       layer 인스턴스 요소는 인덱싱으로 접근\n",
    "class DynamicModel(nn.Module):\n",
    "    def __init__(self,in_in, out_out, h_inout, h_cnt):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_layer = nn.Linear(in_in, h_inout)\n",
    "        self.h_layers =nn.ModuleList( [ nn.Linear(h_inout, h_inout) for _ in range(h_cnt)] )\n",
    "        self.out_layer = nn.Linear(h_inout, out_out)\n",
    "\n",
    "    #학습 진행 콜백 메서드\n",
    "    def forward(self,x):\n",
    "        # 입력층\n",
    "        y=self.in_layer(x)   # y=x1w1+x2w2+x3w3 + b\n",
    "        y=F.relu(y)          # 0 <= y\n",
    "        #은니층\n",
    "        for linear in self.h_layers:\n",
    "            y=linear(y)\n",
    "            y=F.relu(y)\n",
    "        \n",
    "        # 출력층\n",
    "        return self.out_layer(y)\n",
    "        \n",
    "    \n",
    "# 모델인스턴스 생성\n",
    "m1 = DynamicModel(3, 2, 5, 10)\n",
    "\n",
    "# 모델 파라미터 확인\n",
    "for name, param in m1.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1237, 0.0215],\n",
      "        [0.1237, 0.0215],\n",
      "        [0.1237, 0.0215],\n",
      "        [0.1237, 0.0215]], grad_fn=<AddmmBackward0>) torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "## 임시 데이터 생성\n",
    "datats = torch.FloatTensor([[1,3,5], [2,4,6], [3,5,7], [4,6,8]]) # 4행 3열\n",
    "targetts = torch.FloatTensor([[10,9], [8,2], [3,9], [10,12]]) # 4행 2열\n",
    "\n",
    "# 모델 학습\n",
    "d=m1(datats)\n",
    "print(d, d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDynamicModel3(\n",
      "  (input_layer): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (hidden_layers): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=30, bias=True)\n",
      "    (2): Linear(in_features=30, out_features=40, bias=True)\n",
      "    (3): Linear(in_features=40, out_features=50, bias=True)\n",
      "    (4): Linear(in_features=50, out_features=60, bias=True)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=60, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyDynamicModel3(nn.Module):\n",
    "    def __init__(self, in_feature, hidden_layers, out_feature=1):\n",
    "        super(MyDynamicModel3, self).__init__()\n",
    "\n",
    "        # 1. 입력층 정의\n",
    "        self.input_layer = nn.Linear(in_feature, hidden_layers[0] if hidden_layers else out_feature)\n",
    "        \n",
    "        # 2. 은닉층을 동적으로 정의 (빈 리스트가 들어오면 은닉층을 생략)\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.hidden_layers.append(nn.Linear(hidden_layers[i - 1], hidden_layers[i]))\n",
    "\n",
    "        # 3. 출력층 정의 (은닉층이 없으면 입력층에서 바로 출력층으로 연결)\n",
    "        self.output_layer = nn.Linear(hidden_layers[-1] if hidden_layers else in_feature, out_feature)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력층 처리\n",
    "        x = F.relu(self.input_layer(x))\n",
    "\n",
    "        # 은닉층 처리 (은닉층이 있다면 처리)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = F.relu(layer(x))\n",
    "\n",
    "        # 출력층 처리\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# 은닉층 없이 모델을 구성 (입력층 -> 출력층만 존재)\n",
    "model = MyDynamicModel3(in_feature=10, hidden_layers=[10,20,30,40,50,60], out_feature=3)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
